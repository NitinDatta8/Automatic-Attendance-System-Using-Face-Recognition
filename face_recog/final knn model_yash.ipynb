{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import cv2\n",
    "from sklearn import neighbors\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import os.path\n",
    "import pickle\n",
    "from PIL import Image, ImageDraw\n",
    "import face_recognition\n",
    "from face_recognition.face_recognition_cli import image_files_in_folder\n",
    "curd = os.getcwd()\n",
    "try:  \n",
    "    os.mkdir(\"{}/known_people\".format(curd))\n",
    "except:\n",
    "    pass\n",
    "try:  \n",
    "    os.mkdir(\"{}/models\".format(curd))\n",
    "except:\n",
    "    pass\n",
    "try:  \n",
    "    os.mkdir(\"{}/test\".format(curd))\n",
    "except:\n",
    "    pass\n",
    "try:  \n",
    "    os.mkdir(\"{}/unknown_pictures\".format(curd))\n",
    "except:\n",
    "    pass\n",
    "names=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALLOWED_EXTENSIONS = {'png', 'jpg', 'jpeg'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dir, model_save_path=None, n_neighbors=None, knn_algo='ball_tree', verbose=False):\n",
    "   \n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for class_dir in os.listdir(train_dir):\n",
    "        if not os.path.isdir(os.path.join(train_dir, class_dir)):\n",
    "            continue\n",
    "\n",
    "        for img_path in image_files_in_folder(os.path.join(train_dir, class_dir)):\n",
    "            image = face_recognition.load_image_file(img_path)\n",
    "            face_bounding_boxes = face_recognition.face_locations(image)\n",
    "\n",
    "            if len(face_bounding_boxes) != 1:\n",
    "                if verbose:\n",
    "                    print(\"Image {} not suitable for training: {}\".format(img_path, \"Didn't find a face\" if len(face_bounding_boxes) < 1 else \"Found more than one face\"))\n",
    "            else:\n",
    "                X.append(face_recognition.face_encodings(image, known_face_locations=face_bounding_boxes)[0])\n",
    "                y.append(class_dir)\n",
    "\n",
    "    if n_neighbors is None:\n",
    "        n_neighbors = int(round(math.sqrt(len(X))))\n",
    "        if verbose:\n",
    "            print(\"Chose n_neighbors automatically:\", n_neighbors)\n",
    "\n",
    "    knn_clf = neighbors.KNeighborsClassifier(n_neighbors=n_neighbors, algorithm=knn_algo, weights='distance')\n",
    "    knn_clf.fit(X, y)\n",
    "\n",
    "    if model_save_path is not None:\n",
    "        with open(model_save_path, 'wb') as f:\n",
    "            pickle.dump(knn_clf, f)\n",
    "\n",
    "    return knn_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict(frame, knn_clf=None, model_path=None, distance_threshold=0.6):\n",
    "    \n",
    "\n",
    "    if knn_clf is None and model_path is None:\n",
    "        raise Exception(\"Must supply knn classifier either thourgh knn_clf or model_path\")\n",
    "\n",
    "    if knn_clf is None:\n",
    "        with open(model_path, 'rb') as f:\n",
    "            knn_clf = pickle.load(f)\n",
    "\n",
    "    \n",
    "   # X_img = face_recognition.load_image_file(X_img_path)\n",
    "    X_img = frame\n",
    "    X_face_locations = face_recognition.face_locations(X_img)\n",
    "\n",
    "    if len(X_face_locations) == 0:\n",
    "        return []\n",
    "\n",
    "    faces_encodings = face_recognition.face_encodings(X_img, known_face_locations=X_face_locations)\n",
    "\n",
    "    closest_distances = knn_clf.kneighbors(faces_encodings, n_neighbors=1)\n",
    "    are_matches = [closest_distances[0][i][0] <= distance_threshold for i in range(len(X_face_locations))]\n",
    "\n",
    "    return [(pred, loc) if rec else (\"unknown\", loc) for pred, loc, rec in zip(knn_clf.predict(faces_encodings), X_face_locations, are_matches)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#my version\n",
    "def show_prediction_labels_on_image(frame, predictions):\n",
    "    \n",
    "    #pil_image = Image.open(img_path).convert(\"RGB\")\n",
    "    pil_image = Image.fromarray(frame).convert(\"RGB\")\n",
    "    draw = ImageDraw.Draw(pil_image)\n",
    "\n",
    "    for name, (top, right, bottom, left) in predictions:\n",
    "        draw.rectangle(((left, top), (right, bottom)), outline=(0, 0, 255))\n",
    "\n",
    "        \n",
    "        name = name.encode(\"UTF-8\")\n",
    "\n",
    "        text_width, text_height = draw.textsize(name)\n",
    "        draw.rectangle(((left, bottom - text_height - 10), (right, bottom)), fill=(0, 0, 255), outline=(0, 0, 255))\n",
    "        draw.text((left + 6, bottom - text_height - 5), name, fill=(255, 255, 255, 255))\n",
    "\n",
    "    del draw\n",
    "\n",
    "    #pil_image.show()\n",
    "    #cv2.imshow(\"frame\",pil_image)\n",
    "    return np.asarray(pil_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train data creator\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "curd = os.getcwd()\n",
    "name = input()\n",
    "path = \"{}/known_people/{}\".format(curd,name)\n",
    "try:  \n",
    "    os.mkdir(path)\n",
    "except OSError:  \n",
    "    print (\"Creation of the directory %s failed\" % path)\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FPS, 100)\n",
    "rat, frame = cap.read()\n",
    "\n",
    "count=0\n",
    "while count<10:\n",
    "    \n",
    "    rat, frame = cap.read()\n",
    "    cv2.imwrite(\"{}/{}{}.jpg\".format(path,name,count), frame)\n",
    "    count+=1\n",
    "    cv2.imshow('img',frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    time.sleep(1)    \n",
    "\n",
    "\n",
    "cap.release()    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training KNN classifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Choudhary\\Anaconda3\\envs\\mlkit\\lib\\site-packages\\PIL\\Image.py:969: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
      "  'to RGBA images')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "#Trainer\n",
    "if __name__ == \"__main__\":\n",
    "    # STEP 1: Train the KNN classifier and save it to disk\n",
    "    print(\"Training KNN classifier...\")\n",
    "    classifier = train(\"known_people\",\n",
    "                       model_save_path=\"{}/models/trained_knn_model.clf\".format(curd),\n",
    "                       n_neighbors=2)\n",
    "    print(\"Training complete!\")\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test Data Creator\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "curd = os.getcwd()\n",
    "#name = input()\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FPS, 100)\n",
    "rat, frame = cap.read()\n",
    "count=0\n",
    "while count<4:\n",
    "    curtime = time.strftime(\"%Y_%m_%d-%H_%M_%S\")\n",
    "    rat, frame = cap.read()\n",
    "    cv2.imwrite(\"{}/test/{}.jpg\".format(curd,curtime), frame)\n",
    "    count+=1\n",
    "    cv2.imshow('img',frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    time.sleep(1)    \n",
    "\n",
    "\n",
    "cap.release()    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for faces in 0.jpg\n",
      "- Found Shantnu Agarwal at (253, 225)\n",
      "Looking for faces in 1.jpg\n",
      "- Found yo at (357, 276)\n",
      "Looking for faces in 2.jpg\n",
      "Looking for faces in 2019_03_31-00_37_45.jpg\n",
      "- Found yash at (259, 235)\n",
      "Looking for faces in 2019_03_31-00_37_46.jpg\n",
      "- Found yash at (259, 235)\n",
      "Looking for faces in 2019_03_31-00_37_47.jpg\n",
      "- Found yash at (259, 235)\n",
      "- Found yo at (0, 285)\n",
      "Looking for faces in 2019_03_31-00_37_48.jpg\n",
      "- Found yash at (259, 235)\n",
      "Looking for faces in 3.jpg\n",
      "Looking for faces in Dx.jpg\n",
      "- Found DiCap at (167, 39)\n",
      "Looking for faces in Jx.jpg\n",
      "- Found Jason at (46, 55)\n",
      "Looking for faces in momo.jpg\n",
      "- Found Jason at (8, 32)\n",
      "- Found unknown at (117, 122)\n",
      "Looking for faces in XX.jpg\n",
      "- Found unknown at (33, 62)\n",
      "- Found Jason at (89, 30)\n",
      "Looking for faces in Y.jpg\n",
      "- Found DiCap at (1526, 666)\n",
      "- Found unknown at (913, 82)\n",
      "- Found yo at (855, 626)\n",
      "- Found unknown at (325, 641)\n",
      "- Found Jason at (268, 96)\n",
      "- Found unknown at (1491, 133)\n"
     ]
    }
   ],
   "source": [
    "#Still Image Tester\n",
    "curd = os.getcwd()\n",
    "for image_file in os.listdir(r\"{}\\test\".format(curd)):\n",
    "    full_file_path = os.path.join(r\"{}\\test\".format(curd), image_file)\n",
    "\n",
    "    print(\"Looking for faces in {}\".format(image_file))\n",
    "    frame = cv2.imread(full_file_path,-1)\n",
    "\n",
    "    predictions = predict(frame, model_path=r\"{}\\models\\trained_knn_model.clf\".format(curd))\n",
    "\n",
    "    for name, (top, right, bottom, left) in predictions:\n",
    "        print(\"- Found {} at ({}, {})\".format(name, left, top))\n",
    "        names.append(name)\n",
    "    # Display results overlaid on an image\n",
    "    #show_prediction_labels_on_image(frame, predictions)\n",
    "    final_img = show_prediction_labels_on_image(frame, predictions)\n",
    "    cv2.imshow(\"X\",final_img)\n",
    "    cv2.waitKey(1)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Found yash at (282, 223)\n",
      "- Found yash at (270, 199)\n",
      "- Found Shantnu Agarwal at (275, 216)\n",
      "- Found Shantnu Agarwal at (270, 211)\n",
      "- Found yash at (270, 211)\n",
      "- Found Shantnu Agarwal at (270, 211)\n",
      "- Found Shantnu Agarwal at (270, 211)\n",
      "- Found Shantnu Agarwal at (270, 211)\n",
      "- Found yash at (259, 211)\n",
      "- Found Shantnu Agarwal at (270, 211)\n",
      "- Found Shantnu Agarwal at (294, 211)\n",
      "- Found Shantnu Agarwal at (282, 211)\n",
      "- Found yash at (282, 211)\n",
      "- Found Shantnu Agarwal at (259, 211)\n"
     ]
    }
   ],
   "source": [
    "#Live Video tester\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FPS, 100)\n",
    "rat, frame = cap.read()\n",
    "\n",
    "while(True):\n",
    "    rat, frame = cap.read()\n",
    "    predictions = predict(frame, model_path=\"{}/models/trained_knn_model.clf\".format(curd))\n",
    "    for name, (top, right, bottom, left) in predictions:\n",
    "        print(\"- Found {} at ({}, {})\".format(name, left, top))\n",
    "        names.append(name)\n",
    "\n",
    "        # Display results overlaid on an image\n",
    "    show_img = show_prediction_labels_on_image(frame, predictions)\n",
    "    cv2.imshow('img',show_img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "\n",
    "cap.release()    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Present</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Shantnu Agarwal</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yash</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jason</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yo</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DiCap</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Present\n",
       "Shantnu Agarwal        1\n",
       "yash                   1\n",
       "Jason                  0\n",
       "yo                     0\n",
       "DiCap                  0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Attendance System csv maker     \n",
    "namesD=pd.DataFrame(names, columns=[\"Names\"])\n",
    "namesD= namesD[namesD.Names!=\"unknown\"]\n",
    "\n",
    "attendance= pd.DataFrame(namesD.iloc[:,0].value_counts())\n",
    "attendance.rename(index=str,columns={'Names': 'Count'},inplace=True)\n",
    "attendance[\"Present\"] =0\n",
    "\n",
    "attendance[\"Count\"][0] > 5\n",
    "for i in range(attendance.shape[0]):\n",
    "    if(attendance[\"Count\"][i] > 5):\n",
    "        attendance[\"Present\"][i] =1\n",
    "\n",
    "\n",
    "attendance_final=attendance.drop(['Count'],axis=1)\n",
    "attendance_final\n",
    "#attendance_final.to_csv('Attendance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
